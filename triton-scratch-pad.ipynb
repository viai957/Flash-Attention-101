{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass of the kernel\n",
    "\n",
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "@triton.jit\n",
    "def _attn_fwd_inner(\n",
    "    O_block,\n",
    "    l_i,\n",
    "    m_i,\n",
    "    Q_block,\n",
    "    K_block_ptr,\n",
    "    V_block_ptr,\n",
    "    block_index_q,\n",
    "    softmax_scale,\n",
    "    BLOCK_SIZE_Q: tl.constexpr,\n",
    "    BLOCK_SIZE_KV: tl.constexpr,\n",
    "    STAGE: tl.constexpr,\n",
    "    offs_q: tl.constexpr,\n",
    "    offs_kv: tl.constexpr,\n",
    "    SEQ_LEN: tl.constexpr,\n",
    "):\n",
    "    # range of values handled by this stage\n",
    "    if STAGE == 1: # LEft part of diagonal\n",
    "        # From 0 to the left of the diagonal\n",
    "        lo, hi = 0, block_index_q * BLOCK_SIZE_Q\n",
    "    elif STAGE == 2: # Exatly Along the diagonal  \n",
    "        # Used only for the block in which there is transition between non-masked and masked keys\n",
    "        lo, hi = block_index_q * BLOCK_SIZE_Q, (block_index_q + 1) * BLOCK_SIZE_Q\n",
    "        lo = tl.multiple_of(lo, BLOCK_SIZE_Q) \n",
    "    else:\n",
    "        # Only used for non-causal attention\n",
    "        lo, hi = 0, SEQ_LEN\n",
    "\n",
    "    K_block_ptr = tl.advance(K_block_ptr, (0, lo)) \n",
    "    V_block_ptr = tl.advance(V_block_ptr, (lo, 0))\n",
    "\n",
    "    # loop over k, v and update accumulator \n",
    "    for start_kv in range(lo, hi, BLOCK_SIZE_KV):\n",
    "        # Just let the compiler know that start_n is a multiple of BLOCK_N, so the compiler can do optimizations\n",
    "        start_kv = tl.multiple_of(start_kv, BLOCK_SIZE_KV)\n",
    "\n",
    "        # -- compute qk ----\n",
    "        K_block = tl.load(K_block_ptr)\n",
    "        QK_block = tl.dot(Q_block, K_block)\n",
    "\n",
    "        if STAGE == 2: \n",
    "            # Mask is applied when idx_q > indx_k,v\n",
    "            mask = offs_q[:, None] >= (start_kv + offs_kv[None, :])\n",
    "            QK_block = QK_block * softmax_scale + tl.where(mask, 0, -1.0e6)\n",
    "            m_ij = tl.maximum(m_i, tl.max(QK_block, 1))\n",
    "            QK_block -= m_ij[:, None]\n",
    "        else:\n",
    "            # Compute the maximum value of qk or keep the old max value\n",
    "            m_ij = tl.maximum(m_i, tl.max(QK_block, 1) * softmax_scale)\n",
    "            QK_block = QK_block * softmax_scale - m_ij[:, None]\n",
    "\n",
    "        # Compute the exponential of each dot product, so now we are computing exp(qk_ij - m_ij)\n",
    "        P_block = tl.math.exp(QK_block)\n",
    "        # Compute the sum by rows of the attention scores\n",
    "        l_ij = tl.sum(P_block, 1)\n",
    "\n",
    "        # This is the correction factor for the previous l_i\n",
    "        alpha = tl.math.exp(m_i - m_ij) # previous estimate - current estimate\n",
    "        # Apply the correction factor to the previous l_i and add the new l_ij\n",
    "        l_i = l_i * alpha + l_ij\n",
    "\n",
    "        V_block = tl.load(V_block_ptr)\n",
    "        P_block = P_block.to(tl.float16)\n",
    "        # This computes the following: O_new = P x V + O_old * alpha\n",
    "        O_block = O_block * alpha[:, None]\n",
    "        O_block = tl.dot(P_block, V_block, O_block) # O_block += P_block @ V_block\n",
    "\n",
    "        m_i = m_ij\n",
    "\n",
    "        # Move to the next block of K and V\n",
    "        V_block_ptr = tl.advance(V_block_ptr, (BLOCK_SIZE_KV, 0)) # V[Seq_Len, HEAD_DIM]\n",
    "        K_block_ptr = tl.advance(K_block_ptr, (0, BLOCK_SIZE_KV)) # K[HEAD_DIM, Seq_Len]\n",
    "    return O_block, l_i, m_i\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def _attn_fwd(\n",
    "    Q,  # [BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM] # Q[index_batch, index_head, :, :]\n",
    "    K,  # [BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM] # K[index_batch, index_head, :, :]\n",
    "    V,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
    "    softmax_scale,\n",
    "    M,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN\n",
    "    O,  # BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM\n",
    "    stride_Q_batch,\n",
    "    stride_Q_head,\n",
    "    stride_Q_seq,\n",
    "    stride_Q_dim,\n",
    "    stride_K_batch,\n",
    "    stride_K_head,\n",
    "    stride_K_seq,\n",
    "    stride_K_dim,\n",
    "    stride_V_batch,\n",
    "    stride_V_head,\n",
    "    stride_V_seq,\n",
    "    stride_V_dim,\n",
    "    stride_O_batch,\n",
    "    stride_O_head,\n",
    "    stride_O_seq,\n",
    "    stride_O_dim,\n",
    "    BATCH_SIZE,\n",
    "    NUM_HEADS: tl.constexpr,\n",
    "    SEQ_LEN: tl.constexpr,\n",
    "    HEAD_DIM: tl.constexpr,\n",
    "    BLOCK_SIZE_Q: tl.constexpr,\n",
    "    BLOCK_SIZE_KV: tl.constexpr,\n",
    "    STAGE: tl.constexpr,\n",
    "):\n",
    "    tl.static_assert(BLOCK_SIZE_KV <= HEAD_DIM)\n",
    "\n",
    "    # This indicate which block in the sequence length to process\n",
    "    block_index_q = tl.program_id(0)\n",
    "\n",
    "    # This indicates which head and batch to process. Each program is associated with a single head of single batch\n",
    "    index_batch_head = tl.program_id(1)\n",
    "    # This indicates which batch this program is associated with (each batch has NUM_HEADS heads)\n",
    "    index_batch = index_batch_head // NUM_HEADS # Select the right Batch  \n",
    "    # This indicate the poisition of the head in the batch # Select the right Head\n",
    "    index_head = index_batch_head % NUM_HEADS\n",
    "\n",
    "    # This allows to get the (SEQ_LEN, HEAD_DIM) block of Q, K, V by selecting indexing it by batch and head\n",
    "    qkv_offset = (\n",
    "       index_batch.to(tl.int64)* stride_Q_batch # Q[index_batch * stride_Q_batch, :, :, :]\n",
    "       + index_head.to(tl.int64) * stride_Q_head # Q[index_batch * stride_Q_batch + index_head * stride_Q_head, :, :]\n",
    "    )\n",
    "\n",
    "    # We are in Q[index_batch, index_head, block_index_q * BLOCK_SIZE_Q :, : ]\n",
    "    Q_block_ptr = tl.make_block_ptr(# Currently pointing the perticular program to be working with\n",
    "      base= Q + qkv_offset, # Q[index_batch, index_head, :, :]\n",
    "      shape=(SEQ_LEN, HEAD_DIM), \n",
    "      strides=(stride_Q_seq, stride_Q_dim),\n",
    "      offsets=(block_index_q * BLOCK_SIZE_Q, 0),\n",
    "      block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n",
    "      order=(1, 0),\n",
    "    )\n",
    "  \n",
    "    # We are in V[index_batch, index_head, :, :]\n",
    "    V_block_ptr = tl.make_block_ptr( # V[index_batch, index_head, :, :]\n",
    "      base= V + qkv_offset, \n",
    "      shape=(stride_V_seq, stride_V_dim),\n",
    "      offsets=(0,0),\n",
    "      block_shape = (BLOCK_SIZE_KV, HEAD_DIM),\n",
    "      order=(1, 0),\n",
    "    )\n",
    "\n",
    "    # We are in  K[index_batch, index_head, :, :]\n",
    "    \"\"\"\n",
    "    Actually it won't be selecting `everything that is inside` but only the number of elements indicated\n",
    "    by the `block_shape` parameter of each pointer block. You can consider each pointers block to be\n",
    "    a tensor of pointers with the shape indicated by the param `block_shape`\n",
    "    \"\"\"\n",
    "    K_block_ptr = tl.make_block_ptr(\n",
    "      base = K + qkv_offset,\n",
    "      shape=(HEAD_DIM, SEQ_LEN),\n",
    "      strides=(\n",
    "        stride_K_dim,\n",
    "        stride_K_seq,\n",
    "      ), # We invert the strides w.r.t Q, so we can transpose the matrix\n",
    "      offsets=(0,0),\n",
    "      block_shape=(HEAD_DIM, BLOCK_SIZE_KV),\n",
    "      order=(0,1),\n",
    "    )\n",
    "\n",
    "    # In this the selection of the pointer should exactly indicate the right pointer for writing\n",
    "    # Q[index_batch, index_head, block_index_q * BLOCK_SIZE_Q :, :]\n",
    "    O_block_ptr = tl.make_block_ptr(\n",
    "      base= O + qkv_offset,\n",
    "      shape=(SEQ_LEN, HEAD_DIM),\n",
    "      strides=(stride_O_seq, stride_O_dim),\n",
    "      offsets=(block_index_q * BLOCK_SIZE_Q, 0),\n",
    "      block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n",
    "      order=(1,0),\n",
    "    )\n",
    "\n",
    "    # offs_q: the offsets for the tokens in the Q to process\n",
    "    offs_q = block_index_q * BLOCK_SIZE_Q + tl.arange(0, BLOCK_SIZE_Q) \n",
    "    # Suppose program=0, block_size=4, Q[0, 1, 2, 3], Suppose program=3, block_size=4, Q[13, 14, 15, 16]\n",
    "    \"\"\"Each block of query is made up of block_size_q no of Queries. Each Q is a token and its\n",
    "    dimention is not all the token but only the part of the head_dim \"\"\"\n",
    "    # offs_kv: the offsets for the tokens in the K and V sequence to process\n",
    "    \"\"\"We don't skip any values like Q here bcs we are going to multiply the whole K and V with the Q\"\"\"\n",
    "    offs_kv = tl.arange(0, BLOCK_SIZE_KV)\n",
    "    # For KV Suppose block_size = 4  -> [0, 1, 2, 3]\n",
    "    # m_i : the running maximum of each row. We have one for each query\n",
    "    m_i = tl.zeros([BLOCK_SIZE_Q], dtype=tl.float32) - float(\"inf\")\n",
    "    # l_i: the running sum. We have one for each query (as we sum the attention scores by rows)\n",
    "    l_i = tl.zeros([BLOCK_SIZE_Q], dtype=tl.float32) + 1.0 # here +1 is to make the log stable\n",
    "    # acc: the accumilator for the output, which is a group of rows of the O matrix\n",
    "    O_block = tl.zeros([BLOCK_SIZE_Q, HEAD_DIM], dtype=tl.float32)\n",
    "\n",
    "    # load the blocks of Q: it will stay in SRAM throughout\n",
    "    Q_block = tl.load(Q_block_ptr)\n",
    " \n",
    "    # Stage: 3 if casual else 1\n",
    "    if STAGE == 1 or STAGE == 3:\n",
    "      # This step runs for non-casual attention or for the blocks to the left of the diagonal in the casual attention\n",
    "      O_block, l_i, m_i = _attn_fwd_inner(\n",
    "        O_block,\n",
    "        l_i,\n",
    "        m_i,\n",
    "        Q_block,\n",
    "        K_block_ptr,\n",
    "        V_block_ptr,\n",
    "        block_index_q,\n",
    "        softmax_scale,\n",
    "        BLOCK_SIZE_Q,\n",
    "        BLOCK_SIZE_KV,\n",
    "        4 - STAGE,\n",
    "        offs_q,\n",
    "        offs_kv,\n",
    "        SEQ_LEN,\n",
    "      )\n",
    "\n",
    "    if STAGE == 3:\n",
    "      # This step runs for \n",
    "      O_block, l_i, m_i = _attn_fwd_inner(\n",
    "         O_block,\n",
    "            l_i,\n",
    "            m_i,\n",
    "            Q_block,\n",
    "            K_block_ptr,\n",
    "            V_block_ptr,\n",
    "            block_index_q,\n",
    "            softmax_scale,\n",
    "            BLOCK_SIZE_Q,\n",
    "            BLOCK_SIZE_KV,\n",
    "            2,\n",
    "            offs_q,\n",
    "            offs_kv,\n",
    "            SEQ_LEN,\n",
    "      )\n",
    "      # epilogue\n",
    "      m_i += tl.math.log(\n",
    "         l_i\n",
    "      ) # This is needed to compujte the logsumexp for the backward pass\n",
    "      O_block = O_block / l_i[:, None]\n",
    "      m_ptrs = M + index_batch_head * SEQ_LEN + offs_q\n",
    "      tl.store(m_ptrs, m_i)\n",
    "      tl.store(O_block_ptr, O_block.to(O.type.element_ty))\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def _attn_bwd_preprocess(\n",
    "   O,\n",
    "   dO,\n",
    "   Di , # [BATCH_SIZE, NUM_HEADS, SEQ_LEN]\n",
    "   SEQ_LEN,\n",
    "   BLOCK_SIZE_Q: tl.constexpr, # Ex: 4\n",
    "   HEAD_DIM: tl.constexpr,\n",
    "):\n",
    "   # Axis 0: Will indicate the BLOCK_INDEX What is the Block of vectors of \"O\" this program will work with\n",
    "   block_index_q = tl.program_id(0)\n",
    "\n",
    "   # For this we need to skip some Q vector that other program process\n",
    "   # index: 0 * 4 + [0, 1, 2, 3] = [0, 1, 2, 3] | index: 1 * 4 + [0, 1, 2, 3] = [4, 5, 6, 7]\n",
    "   offs_q = block_index_q * BLOCK_SIZE_Q + tl.arange(0, BLOCK_SIZE_Q) # Which block of O we are going to work with\n",
    "   # Axis 1: Which batch and which Head of each batch it is going to work with\n",
    "   index_batch_head = tl.program_id(1) \n",
    "   # Load al the dimentions of each vector\n",
    "   offs_dim = tl.arange(0, HEAD_DIM)\n",
    "   \n",
    "   # Offsets by Hand\n",
    "   # Load a single block of BLOCK_SIZE_Q rows of O\n",
    "   O_block = tl.load( # O [BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM]\n",
    "      O\n",
    "      + index_batch_head * HEAD_DIM * SEQ_LEN # O[index_batch_head * HEAD_DIM * SEQ_LEN, :, :]\n",
    "      + offs_q[:, None] * HEAD_DIM\n",
    "      + offs_dim[None, :]\n",
    "   ) # [BLOCK_SIZE_Q, HEAD_DIM]\n",
    "\n",
    "   # Load a single block of BLOCK_SIZE_Q rows of dO\n",
    "   dO_block = tl.load( # dO [BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM]\n",
    "      dO\n",
    "      + index_batch_head * HEAD_DIM * SEQ_LEN\n",
    "      +  offs_q[:, None] * HEAD_DIM\n",
    "      + offs_dim[None, :]\n",
    "   ).to(tl.float32)\n",
    "\n",
    "   # Compute the Di block with element wise product of dO and O\n",
    "   Di_block = tl.sum(dO_block * O_block, axis=1) # Shape: [BLOCK_SIZE_Q,]\n",
    "   # Store the Di block\n",
    "   Di_block_ptrs = Di + index_batch_head * SEQ_LEN + offs_q\n",
    "   tl.store(Di_block_ptrs, Di_block)\n",
    "\n",
    "@triton.jit\n",
    "def _attn_bed_dq(\n",
    "   Q,\n",
    "   K,\n",
    "   V,\n",
    "   softmax_scale,\n",
    "   dO,\n",
    "   dK,\n",
    "   dV,\n",
    "   M,\n",
    "   D,\n",
    "   stride_batch,\n",
    "   stride_head,\n",
    "   stride_seq,\n",
    "   stride_dim,\n",
    "   NUM_HEADS,\n",
    "   SEQ_LEN,\n",
    "   BLOCK_Q: tl.constexpr,\n",
    "   BLOCK_KV: tl.constexpr,\n",
    "   HEAD_DIM: tl.constexpr,\n",
    "   STAGE: tl.constexpr,\n",
    "):\n",
    "   index_batch_head = tl.program_id(2)\n",
    "   index_batch = index_batch_head // NUM_HEADS\n",
    "   index_head = index_batch_head % NUM_HEADS\n",
    "   offset_batch_head = (stride_batch * index_batch + ) \n",
    "\n",
    "\n",
    "class TritonAttention(torch.autograd.Function):\n",
    "  @staticmethod\n",
    "  def forward(ctx, Q, K, V, casual, softmax_scale):\n",
    "    HEAD_DIM_Q, HEAD_DIM_K = Q.shape[-1], K.shape[-1]\n",
    "    HEAD_DIM_V = V.shape[-1]\n",
    "    \n",
    "    BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM = Q.shape\n",
    "\n",
    "    assert HEAD_DIM_Q == HEAD_DIM_K and HEAD_DIM_V\n",
    "\n",
    "    O = torch.empty_like(Q)\n",
    "    stage = 3 if casual else 1\n",
    "\n",
    "    grid = lambda args: (\n",
    "        # ceil(SEQ_LEN / BLOCK_SIZE_Q) = How many blocks of Q we have\n",
    "        triton.cdiv(SEQ_LEN, args[\"BLOCK_SIZE_Q\"]), # Which group of Queries are we going to work with ?\n",
    "        BATCH_SIZE * NUM_HEADS, # Which head of which batch element are we going to work with ? --- ^\n",
    "        1, # Z is the CUDA launch grid\n",
    "    )\n",
    "\n",
    "    # Number of parallel programs or kernels : (BATCH_SIZE * NUM_HEADS * NUM_BLOCKS_Q)\n",
    "    \n",
    "    # M is logsumexp for the backward pass, one for each query\n",
    "    M = torch.empty(\n",
    "        (BATCH_SIZE, NUM_HEADS, SEQ_LEN), device=Q.device, dtype=torch.float32\n",
    "    )\n",
    "\n",
    "    _attn_fwd[grid](\n",
    "        Q=Q, # Query \n",
    "        K=K, # Key\n",
    "        V=V, # Value\n",
    "        softmax_scale=softmax_scale, # 1/sqrt(HEAD_DIM)\n",
    "        M=M, # Memory Block (L in psudo code of the paper)\n",
    "        O=O, # Output\n",
    "        stride_Q_batch=Q.stride(0), # \n",
    "        stride_Q_head=Q.stride(1),\n",
    "        stride_Q_seq=Q.stride(2),\n",
    "        stride_Q_dim=Q.stride(3),\n",
    "        stride_K_batch=K.stride(0),\n",
    "        stride_K_head=K.stride(1),\n",
    "        stride_K_seq=K.stride(2),\n",
    "        stride_K_dim=K.stride(3),\n",
    "        stride_V_batch=V.stride(0),\n",
    "        stride_V_head=V.stride(1),\n",
    "        stride_V_seq=V.stride(2),\n",
    "        stride_V_dim=V.stride(3),\n",
    "        stride_O_batch=O.stride(0),\n",
    "        stride_O_head=O.stride(1),\n",
    "        stride_O_seq=O.stride(2),\n",
    "        stride_O_dim=O.stride(3),\n",
    "        BATCH_SIZE=Q.shape[0],\n",
    "        NUM_HEADS=Q.shape[1],\n",
    "        SEQ_LEN=Q.shape[2],\n",
    "        HEAD_DIM=HEAD_DIM_K,\n",
    "        STAGE=stage,\n",
    "    )\n",
    "\n",
    "    ctx.save_for_backward(Q, K, V, O, M)\n",
    "    ctx.grid = grid\n",
    "    ctx.softmax_scale = softmax_scale\n",
    "    ctx.HEAD_DIM = HEAD_DIM_K\n",
    "    ctx.casual = casual\n",
    "    return 0\n",
    "\n",
    "  @staticmethod\n",
    "  def backward(ctx, dO):\n",
    "     Q, K, V, O, M = ctx.saved_tensors\n",
    "\n",
    "     assert dO.is_contiguous()\n",
    "     assert Q.stride() == K.stride() == V.stride() == O.stride() == dO.stride()\n",
    "     dQ = torch.empty_like(Q)\n",
    "     dK = torch.empty_like(K)\n",
    "     dV = torch.empty_like(V)\n",
    "\n",
    "     BATCH_SIZE, NUM_HEADS, SEQ_LEN = Q.shape[:3]\n",
    "     NUM_WARPS, NUM_STAGES = 4, 3\n",
    "     BLOCK_SIZE_MICRO, BLOCK_SIZE_MACRO = 32, 128\n",
    "     # Precompute all the Di elements\n",
    "     # Launch Grid for each batch and each head\n",
    "     preprocess_grid = (SEQ_LEN // BLOCK_SIZE_MICRO, BATCH_SIZE * NUM_HEADS)\n",
    "     Di = torch.empty_like(M) # Shape: (BATCH_SIZE, NUM_HEADS, SEQ_LEN)\n",
    "\n",
    "     # Compute all the elements Di\n",
    "     _attn_bwd_preprocess[preprocess_grid](\n",
    "        O=O,\n",
    "        dO=dO,\n",
    "        Di=Di,\n",
    "        SEQ_LEN=SEQ_LEN,\n",
    "        BLOCK_SIZE_Q=BLOCK_SIZE_MICRO,\n",
    "        HEAD_DIM=ctx.HEAD_DIM,\n",
    "     )\n",
    "\n",
    "     grid = (SEQ_LEN // BLOCK_SIZE_MACRO, 1, BATCH_SIZE * NUM_HEADS)\n",
    "     \n",
    "     stage = 3 if ctx.casual else 1\n",
    "\n",
    "     # Pivit the KV and iterate over all the Q blocks\n",
    "     _attn_bkwd_dk_dv[grid](\n",
    "        Q=Q,\n",
    "        K=K,\n",
    "        V=V,\n",
    "        softmax_scale=ctx.softmax_scale,\n",
    "        dO=dO,\n",
    "        dQ=dQ,\n",
    "        dk=dK,\n",
    "        dV=dV,\n",
    "        M=M,\n",
    "        Di=Di,\n",
    "        stride_batch=Q.stride(0),\n",
    "        stride_head=Q.stride(1),\n",
    "        stride_seq=Q.stride(2),\n",
    "        stride_dim=Q.stride(3),\n",
    "        NUM_HEADS=NUM_HEADS,\n",
    "        SEQ_LEN=SEQ_LEN,\n",
    "        BLOCK_Q=BLOCK_SIZE_MACRO,\n",
    "        BLOCK_KV=BLOCK_SIZE_MICRO,\n",
    "        HEAD_DIM=ctx.HEAD_DIM,\n",
    "        STAGE=stage,\n",
    "        num_warps=NUM_WARPS,\n",
    "        num_stages=NUM_STAGES,\n",
    "     )\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "def test_op(BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM, casual, dtype=torch.float16):\n",
    "  Q = (\n",
    "      torch.empty(\n",
    "          (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
    "      )\n",
    "      .normal_(mean=0.0, std=0.5)\n",
    "      .requires_grad_()\n",
    "  )\n",
    "  K = ( \n",
    "      torch.empty(\n",
    "          (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
    "      )\n",
    "      .normal_(mean=0.0, std=0.5)\n",
    "      .requires_grad_()\n",
    "  )\n",
    "  V = (\n",
    "      torch.empty(\n",
    "          (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
    "      )\n",
    "      .normal_(mean=0.0, std=0.5)\n",
    "      .requires_grad_()\n",
    "  )\n",
    "  \n",
    "  softmax_scale = 1 / (HEAD_DIM**0.5) # Q K^T / sqrt(HEAD_DIM)\n",
    "  dO = torch.randn_like(0) # Needed for backward pass \n",
    "\n",
    "  # reference implementation (naive implimentation wrt CUDA and PyTorch)\n",
    "  MASK = torch.tril(torch.ones((SEQ_LEN, SEQ_LEN), device=\"cuda\"))\n",
    "  P = torch.mathmul(Q, K.transpose(2, 3)) * softmax_scale\n",
    "  if casual:\n",
    "    P[:, :, MASK == 0] = float(\"-inf\")\n",
    "  P = torch.softmax(P.float(\"inf\")).half()\n",
    "  ref_O = torch.matmul(P, V)\n",
    "  ref_O .backward()\n",
    "  ref_dV, V.grad = V.grad.clone(), None\n",
    "  ref_dK, K.grad = K.grad.clone(), None\n",
    "  ref_dQ, Q.grad = Q.grad.clone(), None\n",
    "\n",
    "  # triton implimentation \n",
    "  tri_out = TritonAttention.apply(Q,K,V, casual, softmax_scale).half()\n",
    "  tri_out.backward(dO)\n",
    "  tri_dV, V.grad = V.grad.clone(), None\n",
    "  tri_dK, K.grad = K.grad.clone(), None\n",
    "  tri_dQ, Q.grad = Q.grad.clone(), None\n",
    "\n",
    "  # Compare\n",
    "  rtrol = 0.0\n",
    "  atol = 1e-2 \n",
    "  # Absolute Diffrence\n",
    "  assert torch.allclose(ref_O, tri_out, atol=atol, rtol=rtol)\n",
    "  assert torch.allclose(ref_dK, tri_dK, atol=atol, rtol=rtol)\n",
    "  assert torch.allclose(ref_dV, tri_dV, atol=atol, rtol=rtol)\n",
    "  assert torch.allclose(ref_dQ, tri_dQ, atol=atol, rtol=rtol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "\n",
    "\n",
    "@triton.jit\n",
    "def _attn_fwd_inner(\n",
    "    Q,\n",
    "    K,\n",
    "    V, \n",
    "    softmax_scale,\n",
    "    M,\n",
    "    O,\n",
    "    stride_Q_batch, stride_Q_head, stride_Q_seq, stride_Q_dim,\n",
    "    stride_K_batch, stride_K_head, stride_K_seq, stride_K_dim,\n",
    "    stride_V_batch, stride_V_head, stride_V_seq, stride_V_dim,\n",
    "    stride_O_batch, stride_O_head, stride_O_seq, stride_O_dim,\n",
    "    BATCH_SIZE, \n",
    "    NUM_HEADS: tl.constexpr,\n",
    "    SEQ_LEN: tl.constexpr,\n",
    "    HEAD_DIM: tl.constexpr,\n",
    "    BLOCK_SIZE_Q: tl.constexpr,\n",
    "    BLOCK_SIZE_KV: tl.constexpr,\n",
    "    STAGE: tl.constexpr, \n",
    "):\n",
    "    tl.static_assert(BLOCK_SIZE_KV <= HEAD_DIM)\n",
    "\n",
    "    # This indicate which block in the sequence length to process\n",
    "    block_index_q = tl.program_id(0)\n",
    "\n",
    "    # This indicates which head and batch to process. Each program is associated with a single head of single batch\n",
    "    index_batch_head = tl.program_id(1)\n",
    "    # THis indicate which batch this program is associated with (each batch has NUM_HEADS heads)\n",
    "    index_batch = index_batch_head // NUM_HEADS\n",
    "    # This indicate the position of the head in the batch\n",
    "    index_head = index_batch_head % NUM_HEADS\n",
    "\n",
    "    # This allows to get the (N_CTX, HEAD_DIM) block in Q, K, V by selecting indexing it by batch and head\n",
    "    qkv_offset = (\n",
    "        index_batch.to(tl.int64) * stride_Q_batch # Q[index_batch * stride_Q_batch, :, :, :]\n",
    "        + index_head.to(tl.int64) * stride_Q_head # Q[index_batch * stride_Q_batch + index_head * stride_Q_head, :, :]\n",
    "    )\n",
    "\n",
    "    # We are in Q[index_batch, index_head, block_index_q * BLOCK_SIZE_Q :, :]\n",
    "    Q_block_ptr = tl.make_block_ptr(\n",
    "        base = Q + qkv_offset, # Q[index_batch, index_head, :, :]\n",
    "        shape = (SEQ_LEN, HEAD_DIM),\n",
    "        strides = (stride_Q_seq, stride_Q_dim),\n",
    "        offsets = (block_index_q * BLOCK_SIZE_Q, 0),\n",
    "        block_shape=(BLOCK_SIZE_Q, HEAD_DIM),\n",
    "        order=(1,0),\n",
    "    )\n",
    "\n",
    "    V_block_ptr = tl.make_block_ptr(\n",
    "        base= V + qkv_offset,\n",
    "        shape=(stride_V_seq, stride_V_dim),\n",
    "        offsets=(0,0),\n",
    "        block_shape=(BLOCK_SIZE_KV, HEAD_DIM),\n",
    "        order=(1,0),\n",
    "    )\n",
    "\n",
    "    K_block_ptr = tl.make_block_ptr(\n",
    "        base = K + qkv_offset,\n",
    "        shape = (HEAD_DIM, SEQ_LEN),\n",
    "        str\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class TritonAttention(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, Q, K, V, casual, softmax_scale):\n",
    "        HEAD_DIM_Q, HEAD_DIM_K = Q.shape[-1], K.shape[-1]\n",
    "        HEAD_DIM_V = V.shape[-1]\n",
    "\n",
    "        BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM = Q.shape\n",
    "\n",
    "        assert HEAD_DIM_Q == HEAD_DIM_K and HEAD_DIM_V\n",
    "\n",
    "        O = torch.empty_like(Q)\n",
    "        stage = 3 if casual else 1\n",
    "\n",
    "        grid = lambda args: (\n",
    "            # ceil(SEQ_LEN / BLOCK_SIZE_Q) = How many blocks of Q we have\n",
    "            triton.cdiv(SEQ_LEN, args[\"BLOCK_SIZE_Q\"]), # Which group of Queries are we going to work with ?\n",
    "            BATCH_SIZE * NUM_HEADS, # Which head of which batch element are we going to work with ?\n",
    "            1, # Z is the CUDA launch grid\n",
    "        )\n",
    "\n",
    "        # Number of parallel programs or kernels : (BATCH_SIZE * NUM_HEADS * NUM_BLOCKS_Q)\n",
    "\n",
    "        # M is logsumexp for the backward pass, one for each query\n",
    "        M = torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN), device=Q.device, dtype=torch.float32\n",
    "        )\n",
    "\n",
    "        _attn_fwd[grid](\n",
    "            Q=Q,\n",
    "            K=K,\n",
    "            V=V,\n",
    "            softmax_scale=softmax_scale,\n",
    "            M=M,\n",
    "            O=O,\n",
    "            stride_Q_batch=Q.stride(0),\n",
    "            stride_Q_head=Q.stride(1),\n",
    "            stride_Q_seq=Q.stride(2),\n",
    "            stride_Q_dim=Q.stride(3),\n",
    "            stride_K_batch=K.stride(0),\n",
    "            stride_K_head=K.stride(1),\n",
    "            stride_K_seq=K.stride(2),\n",
    "            stride_K_dim=K.stride(3),\n",
    "            stride_V_batch=V.stride(0),\n",
    "            stride_V_head=V.stride(1),\n",
    "            stride_V_seq=V.stride(2),\n",
    "            stride_V_dim=V.stride(3),\n",
    "            stride_O_batch=O.stride(0),\n",
    "            stride_O_head=O.stride(1),\n",
    "            stride_O_seq=O.stride(2),\n",
    "            stride_O_dim=O.stride(3),\n",
    "            BATCH_SIZE=Q.shape[0],\n",
    "            NUM_HEADS=Q.shape[1],\n",
    "            SEQ_LEN=Q.shape[2],\n",
    "            HEAD_DIM=HEAD_DIM_K,\n",
    "            STAGE=stage,\n",
    "        )\n",
    "\n",
    "        ctx.save_for_backward(Q, K, V, O, M)\n",
    "        ctx.grid = grid\n",
    "        ctx.softmax_scale = softmax_scale\n",
    "        ctx.HEAD_DIM = HEAD_DIM_K\n",
    "        ctx.casual = casual\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def test_op(BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM, casual, dtype=torch.float16):\n",
    "    Q = (\n",
    "        torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
    "        )\n",
    "        .normal_(mean=0.0, std=0.5)\n",
    "        .requires_grad_()\n",
    "    )\n",
    "    K = (\n",
    "        torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
    "        )\n",
    "        .normal_(mean=0.0, std=0.5)\n",
    "        .requires_grad_()\n",
    "    )\n",
    "    V = (\n",
    "        torch.empty(\n",
    "            (BATCH_SIZE, NUM_HEADS, SEQ_LEN, HEAD_DIM), dtype=dtype, device=\"cuda\"\n",
    "        )\n",
    "        .normal_(mean=0.0, std=0.5)\n",
    "        .requires_grad_()\n",
    "    )\n",
    "\n",
    "    softmax_scale = 1 / (HEAD_DIM ** 0.5)  # Q K^T / sqrt(HEAD_DIM)\n",
    "    dO = torch.randn_like(Q) # Output\n",
    "\n",
    "    # reference implimentation\n",
    "    MASK = torch.tril(torch.ones((SEQ_LEN, SEQ_LEN), device=\"cuda\"))\n",
    "    P = torch.matmul(Q, K.transpose(2, 3)) * softmax_scale\n",
    "    if casual:\n",
    "        P[:, :, MASK == 0] = float(\"-inf\")\n",
    "    P = torch.softmax(P.float(), dim=-1).half()\n",
    "    ref_O = torch.matmul(P, V)\n",
    "    ref_O.backward(dO)\n",
    "    ref_dV, V.grad = V.grad.clone(), None\n",
    "    ref_dK, K.grad = K.grad.clone(), None\n",
    "    ref_dQ, Q.grad = Q.grad.clone(), None\n",
    "\n",
    "    # triton implimentation\n",
    "    tri_out = TritonAttention.apply(Q, K, V, casual, softmax_scale).half()\n",
    "    tri_out.backward(dO)\n",
    "    tri_dV, V.grad = V.grad.clone(), None\n",
    "    tri_dK, K.grad = K.grad.clone(), None\n",
    "    tri_dQ, Q.grad = Q.grad.clone(), None\n",
    "\n",
    "    # Compare\n",
    "    rtol = 0.0\n",
    "    atol = 1e-2\n",
    "    assert torch.allclose(ref_O, tri_out, atol=atol, rtol=rtol)\n",
    "    assert torch.allclose(ref_dK, tri_dK, atol=atol, rtol=rtol)\n",
    "    assert torch.allclose(ref_dV, tri_dV, atol=atol, rtol=rtol)\n",
    "    assert torch.allclose(ref_dQ, tri_dQ, atol=atol, rtol=rtol)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_op(BATCH_SIZE=8, NUM_HEADS=8, SEQ_LEN=1024, HEAD_DIM=64, casual=True)\n",
    "    test_op(BATCH_SIZE=8, NUM_HEADS=8, SEQ_LEN=1024, HEAD_DIM=64, casual=False)\n",
    "    print(\"PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema being used:\n",
      "{\n",
      "  \"properties\": {\n",
      "    \"brand\": {\n",
      "      \"title\": \"Brand\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"model\": {\n",
      "      \"title\": \"Model\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"car_type\": {\n",
      "      \"title\": \"Car Type\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"brand\",\n",
      "    \"model\",\n",
      "    \"car_type\"\n",
      "  ],\n",
      "  \"title\": \"CarDescription\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "\n",
      "\n",
      "Response:\n",
      "{ \"brand\": \"Ford\", \"model\": \"Mustang GT\", \"car_type\": \"Muscle Car\" }\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "# Define a simple schema\n",
    "class CarDescription(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    car_type: str\n",
    "\n",
    "# Get the schema\n",
    "json_schema = CarDescription.model_json_schema()\n",
    "\n",
    "# Print the schema we're using\n",
    "print(\"Schema being used:\")\n",
    "print(json.dumps(json_schema, indent=2))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://dev1-trusttgpt-ccep.trustt.com/v1\",\n",
    "    api_key=\"EMPTY\",\n",
    ")\n",
    "\n",
    "# Make the request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Generate a JSON with the brand, model, and car_type of the most iconic car from the 90's\",\n",
    "        }\n",
    "    ],\n",
    "    extra_body={\"guided_json\": json_schema},\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(\"Response:\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "# Define the schema for loan offer response\n",
    "class LoanOfferResponse(BaseModel):\n",
    "    has_customer_selected_tenure: str\n",
    "    selected_tenure_value: str\n",
    "    has_customer_selected_loan_amount: str\n",
    "    loan_amount_value: str\n",
    "    loan_details_verified: str\n",
    "    assistant_response: str\n",
    "    other_flag: str\n",
    "\n",
    "# Test parameters\n",
    "minimum_amount = 10000\n",
    "approvedOfferAmount = 500000\n",
    "applicableTenureList = [12, 24, 36, 48, 60]\n",
    "\n",
    "# Create the system prompt with the parameters\n",
    "system_prompt=f\"\"\"You are TrusttGPT, a JSON Response generator for Pre-Approved Offer for the Loan Origination process . Your role is to find whether customer intent is related to pre-approved loan offer and guide the customer through the process of selecting the loan amount and tenure.\n",
    "\n",
    "All the values should be in the JSON format.\n",
    "{{\n",
    "  \"has_customer_selected_tenure\": \"\",\n",
    "  \"selected_tenure_value\": \"\",\n",
    "  \"has_customer_selected_loan_amount\":\"\" ,\n",
    "  \"loan_amount_value\": \"\",\n",
    "  \"loan_details_verified\": \"\",\n",
    "  \"assistant_response\": \"\",\n",
    "  \"other_flag\":\"\" \n",
    "}}\n",
    "Rules to follow:\n",
    "Important: The values provided by the customer may just be numericals without any text. Just extract the values and set the corresponding values based on the customer inputs.\n",
    "\n",
    "1.loan_amount_value: Extract the loan amount provided by the customer\n",
    "If tenure is in years (single-digit), convert to months (1 year = 12 months). Ensure the final value is in {applicableTenureList}. If not in the list, prompt the customer to select a valid tenure.\n",
    "3.has_customer_selected_tenure & has_customer_selected_loan_amount: \"yes\" or \"no\" based on whether values are selected.\n",
    "4.loan_details_verified: yes if the customer has verified the details otherwise no.\n",
    "5.assistant_response: Guide the customer based on their inputs, ensuring they select values\n",
    "6.other_flag: \"yes\" or \"no\" based on whether the customer wants to update the values, change the values .\n",
    "\n",
    "FLOW:\n",
    "- The customer can provide the loan amount and tenure values, then set the corresponding ** loan_amount_value ** and ** selected_tenure_value ** to the provided values and ** other_flag ** to \"no\".\n",
    "- Customer can provide the loan amount and tenure values in a single message or in multiple messages.\n",
    "-- the tenure provided by the customer should be in months. If the tenure is explicitly provided in years, only convert it to months and set the ** selected_tenure_value ** to the converted value.\n",
    "- If the customer provides the loan amount then extract the loan amount, set corresponding ** loan_amount_value **to the extracted value and  ask the customer to provide the tenure value and set ** other_flag ** to \"no\".\n",
    "- If the customer provides both loan amount and tenure values, then prompt the customer to verify the details and set ** other_flag ** to \"no\".\n",
    "- If the customer verifies the details by saying affirmations like \"yes\",\"confirm\",\"proceed\" etc, set ** loan_details_verified ** to \"yes\"\n",
    "- If the customer wants to update the values, set ** other_flag ** to \"yes\" and prompt the customer to provide the updated values.\n",
    "- If the customer wants to know about the offer details or any other information, provide the necessary details based on the approved offer amount from {minimum_amount} to {approvedOfferAmount} and tenure from {applicableTenureList} and set ** other_flag ** to \"yes\" for Q and A. Strictly do not use the given range to validate the values.\n",
    "    For example:\n",
    "        - If the customer ask how much loan amount can i get, can't i get more loan amount, set ** other_flag ** to \"yes\" and provide the details based on the approved offer details.\n",
    "        - If the customer asks can i get a loan of << value greater than the approved offer amount >>, set ** other_flag ** to \"yes\" and prompt the approved offer details from the given amount range.\n",
    "        - Similarly, if the customer ask about the tenure, set ** other_flag ** to \"yes\" and provide the details based on the approved tenure list.\n",
    "        - If the customer opted for loan details updation and provides the updated values, then stricltly do not validate the loan details set ** other_flag ** to \"no\" and also set the corresponding ** loan_amount_value ** and ** selected_tenure_value ** to the provided values irrespective of the given range.\n",
    "- If the customer changes the values, then extract the new values and set ** other_flag ** to \"no\" and prompt the customer according to the flow.\n",
    "- Strictly do not validate the values, only extract the values regardless of the validity. The validation will be done by the system.\n",
    "- Do not make up assistance responses on your own. Strictly follow the flow and provide the responses based on the customer inputs.\n",
    "IMPORTANT:\n",
    "- ** STRICTLY DO NOT VALIDATE THE VALUES **\n",
    "- ** STRICTLY SET other_flag to \"no\" WHEN YOU EXTRACT LOAN AMOUNT AND TENURE VALUES**\n",
    "- ** STRICTLY SET THE CORRESPONDING VALUES BASED ON THE CUSTOMER INPUTS**\n",
    "- Strictly go through the rules and follow the flow to guide the customer through the process.\n",
    "- Do not validate the values, only extract the values provided by the customer. System will validate the values and will provide you the context accordingly. and set ** other_flag ** to \"no\".\n",
    "- Do not provide any extra information or details on your own.\n",
    "\"\"\"\n",
    "\n",
    "# Get the schema\n",
    "json_schema = LoanOfferResponse.model_json_schema()\n",
    "\n",
    "# Initialize client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://dev1-trusttgpt-ccep.trustt.com/v1\",\n",
    "    api_key=\"EMPTY\",\n",
    ")\n",
    "\n",
    "class ConversationManager:\n",
    "    def __init__(self):\n",
    "        self.conversation_history: List[Dict] = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt}\n",
    "        ]\n",
    "        self.previous_responses = []\n",
    "    \n",
    "    def get_loan_response(self, user_message: str):\n",
    "        try:\n",
    "            # Add user message to conversation history\n",
    "            self.conversation_history.append({\"role\": \"user\", \"content\": user_message})\n",
    "            \n",
    "            # Make the request with full conversation history\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "                messages=self.conversation_history,\n",
    "                extra_body={\"guided_json\": json_schema},\n",
    "            )\n",
    "            \n",
    "            # Get and parse the response\n",
    "            response_text = response.choices[0].message.content\n",
    "            parsed_response = json.loads(response_text)\n",
    "            \n",
    "            # Validate with Pydantic\n",
    "            validated_response = LoanOfferResponse(**parsed_response)\n",
    "            \n",
    "            # Store the response\n",
    "            self.previous_responses.append(validated_response)\n",
    "            \n",
    "            # Add assistant response to conversation history\n",
    "            self.conversation_history.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response_text\n",
    "            })\n",
    "            \n",
    "            return validated_response\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def print_conversation_state(self):\n",
    "        print(\"\\nConversation State:\")\n",
    "        print(\"-\" * 50)\n",
    "        for i, response in enumerate(self.previous_responses, 1):\n",
    "            print(f\"\\nStep {i}:\")\n",
    "            print(json.dumps(response.model_dump(), indent=2))\n",
    "\n",
    "# Example usage in Jupyter notebook\n",
    "# Initialize conversation\n",
    "conversation = ConversationManager()\n",
    "\n",
    "# Test sequential interactions\n",
    "def test_interaction(message: str):\n",
    "    print(f\"\\nUser: {message}\")\n",
    "    print(\"-\" * 50)\n",
    "    response = conversation.get_loan_response(message)\n",
    "    if response:\n",
    "        print(\"Latest Response:\")\n",
    "        print(json.dumps(response.model_dump(), indent=2))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User: I want a loan of 200000\n",
      "--------------------------------------------------\n",
      "Latest Response:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"We've previously reviewed your loan application for a loan amount of 200000 and tenure of 2 years. Based on that, we can offer you a loan with an interest rate of 8.5% per annum. Your estimated monthly installment would be approximately 10000. Would you like to proceed with the loan application?\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "User: I want it for 2 years\n",
      "--------------------------------------------------\n",
      "Latest Response:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Congratulations! Your loan application has been confirmed. Your loan details are as follows: Loan Amount: 200000, Tenure: 2 years, Interest Rate: 8.5% per annum, Estimated Monthly Installment: 10000. Please review the loan details carefully and confirm if you would like to proceed with the loan disbursement.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "User: Yes, confirm these details\n",
      "--------------------------------------------------\n",
      "Latest Response:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Loan Application Confirmed! Your loan details are as follows: Loan Amount: 200000, Tenure: 2 years, Interest Rate: 8.5% per annum, Estimated Monthly Installment: 10000. We will proceed with the loan disbursement. Please wait for our loan officer to contact you for further instructions.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Conversation State:\n",
      "--------------------------------------------------\n",
      "\n",
      "Step 1:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"false\",\n",
      "  \"selected_tenure_value\": \"\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"Please select the tenure for your loan. We can assist you with a range of tenure options from 1 to 15 years. Please enter the desired tenure in years.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 2:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"Based on your selected loan amount of 200000 and tenure of 2 years, we can offer you a loan with an interest rate of 8.5% per annum. Your estimated monthly installment would be approximately 10000. Would you like to proceed with the loan application?\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 3:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Congratulations! Your loan application has been confirmed. Your loan details are as follows: Loan Amount: 200000, Tenure: 2 years, Interest Rate: 8.5% per annum, Estimated Monthly Installment: 10000. Please review the loan details carefully and confirm if you would like to proceed with the loan disbursement.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 4:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Yes, we can consider a higher loan amount for you. However, please note that the interest rate and tenure may vary based on the increased loan amount. Would you like to consider an option of 250000, 300000, or 350000? Please select one of the above options or enter a custom loan amount.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 5:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=300000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"Based on your new loan amount of 300000 and tenure of 2 years, we can offer you a loan with an interest rate of 8.8% per annum. Your estimated monthly installment would be approximately 12500. Would you like to proceed with the loan application?\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 6:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"We've previously reviewed your loan application for a loan amount of 200000 and tenure of 2 years. Based on that, we can offer you a loan with an interest rate of 8.5% per annum. Your estimated monthly installment would be approximately 10000. Would you like to proceed with the loan application?\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 7:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Congratulations! Your loan application has been confirmed. Your loan details are as follows: Loan Amount: 200000, Tenure: 2 years, Interest Rate: 8.5% per annum, Estimated Monthly Installment: 10000. Please review the loan details carefully and confirm if you would like to proceed with the loan disbursement.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 8:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Loan Application Confirmed! Your loan details are as follows: Loan Amount: 200000, Tenure: 2 years, Interest Rate: 8.5% per annum, Estimated Monthly Installment: 10000. We will proceed with the loan disbursement. Please wait for our loan officer to contact you for further instructions.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "User: Can I get more loan amount?\n",
      "--------------------------------------------------\n",
      "Latest Response:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Yes, we can consider a higher loan amount for you. However, please note that the interest rate and tenure may vary based on the increased loan amount. Would you like to consider an option of 250000, 300000, or 350000? Please select one of the above options or enter a custom loan amount.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "User: I want to change the loan amount to 300000\n",
      "--------------------------------------------------\n",
      "Latest Response:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=300000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"Based on your new loan amount of 300000 and tenure of 2 years, we can offer you a loan with an interest rate of 8.8% per annum. Your estimated monthly installment would be approximately 12500. Would you like to proceed with the loan application?\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Conversation State:\n",
      "--------------------------------------------------\n",
      "\n",
      "Step 1:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"false\",\n",
      "  \"selected_tenure_value\": \"\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"Please select the tenure for your loan. We can assist you with a range of tenure options from 1 to 15 years. Please enter the desired tenure in years.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 2:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"Based on your selected loan amount of 200000 and tenure of 2 years, we can offer you a loan with an interest rate of 8.5% per annum. Your estimated monthly installment would be approximately 10000. Would you like to proceed with the loan application?\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 3:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Congratulations! Your loan application has been confirmed. Your loan details are as follows: Loan Amount: 200000, Tenure: 2 years, Interest Rate: 8.5% per annum, Estimated Monthly Installment: 10000. Please review the loan details carefully and confirm if you would like to proceed with the loan disbursement.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 4:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Yes, we can consider a higher loan amount for you. However, please note that the interest rate and tenure may vary based on the increased loan amount. Would you like to consider an option of 250000, 300000, or 350000? Please select one of the above options or enter a custom loan amount.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 5:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=300000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"Based on your new loan amount of 300000 and tenure of 2 years, we can offer you a loan with an interest rate of 8.8% per annum. Your estimated monthly installment would be approximately 12500. Would you like to proceed with the loan application?\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 6:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"We've previously reviewed your loan application for a loan amount of 200000 and tenure of 2 years. Based on that, we can offer you a loan with an interest rate of 8.5% per annum. Your estimated monthly installment would be approximately 10000. Would you like to proceed with the loan application?\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 7:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Congratulations! Your loan application has been confirmed. Your loan details are as follows: Loan Amount: 200000, Tenure: 2 years, Interest Rate: 8.5% per annum, Estimated Monthly Installment: 10000. Please review the loan details carefully and confirm if you would like to proceed with the loan disbursement.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 8:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Loan Application Confirmed! Your loan details are as follows: Loan Amount: 200000, Tenure: 2 years, Interest Rate: 8.5% per annum, Estimated Monthly Installment: 10000. We will proceed with the loan disbursement. Please wait for our loan officer to contact you for further instructions.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 9:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=200000\",\n",
      "  \"loan_details_verified\": \"true\",\n",
      "  \"assistant_response\": \"Yes, we can consider a higher loan amount for you. However, please note that the interest rate and tenure may vary based on the increased loan amount. Would you like to consider an option of 250000, 300000, or 350000? Please select one of the above options or enter a custom loan amount.\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n",
      "\n",
      "Step 10:\n",
      "{\n",
      "  \"has_customer_selected_tenure\": \"true\",\n",
      "  \"selected_tenure_value\": \"2\",\n",
      "  \"has_customer_selected_loan_amount\": \"true\",\n",
      "  \"loan_amount_value\": \">=300000\",\n",
      "  \"loan_details_verified\": \"false\",\n",
      "  \"assistant_response\": \"Based on your new loan amount of 300000 and tenure of 2 years, we can offer you a loan with an interest rate of 8.8% per annum. Your estimated monthly installment would be approximately 12500. Would you like to proceed with the loan application?\",\n",
      "  \"other_flag\": \"false\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test sequential conversation\n",
    "# Step 1: Initial loan amount request\n",
    "test_interaction(\"I want a loan of 200000\")\n",
    "\n",
    "# Step 2: Tenure selection\n",
    "test_interaction(\"I want it for 2 years\")\n",
    "\n",
    "# Step 3: Verification\n",
    "test_interaction(\"Yes, confirm these details\")\n",
    "\n",
    "# View entire conversation state\n",
    "conversation.print_conversation_state()\n",
    "\n",
    "# Continue with more interactions\n",
    "test_interaction(\"Can I get more loan amount?\")\n",
    "test_interaction(\"I want to change the loan amount to 300000\")\n",
    "\n",
    "# View updated conversation state\n",
    "conversation.print_conversation_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
